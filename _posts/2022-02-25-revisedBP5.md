---
layout: post
title: PIC 16B Blog Post 5!
---

Hello dear reader and welcome back to another blog post! Today's task is to teach a machine learning algorithm to distinguish betweeen pictures of dogs and cats. To do so, we will be making use of a Python package called TensorFlow. Let's get started!

Today's post is loosely based off of the following tutorial: https://www.tensorflow.org/tutorials/images/transfer_learning

### Load Packages and Obtain Data

First let's go ahead and import the libraries we will need for our task today


```python
import os
import tensorflow as tf
from tensorflow.keras import datasets, layers, models, utils
import matplotlib.pyplot as plt
```

The following code creates a TensorFlow dataset that we will use for training, validation, and testing. Our dataset consists of labeled images of dogs and cats. As can be seen by the `batch_size` and `shuffle` variables, each time we extract data, we will shuffle our data and randomly get 32 images from each data set. We now have training data, validation data, and testing data.


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)


class_names = train_dataset.class_names
```

    Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
    68608000/68606236 [==============================] - 2s 0us/step
    68616192/68606236 [==============================] - 2s 0us/step
    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.


Lastly, this next chunk of code allows us to rapidly read in our data. Don't worry too much about this code right now!


```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

### Working with Datasets

First, let's go ahead and visualize the dataset we are working with! We will take small chunks of data (32 images with labels) using the `take` method in `train_dataset.take(1)`. Let's take a look at some of the images from our dataset down below.


```python
plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
  for i in range(6):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")
```


    
![image-example.png](/images/output_7_0.png)
    


### Check Label Frequencies

How many images do we have in our dataset? We can compute the answer to this using the code chunk below. Our `labels_iterator` allows us to iterate over each image in our entire dataset. As we iterate over our data, we will sum up the number of images of cats and dogs.


```python
labels_iterator = train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
cats = 0
dogs = 0
total = 0

for i in labels_iterator:
  if i == 0:
    cats += 1
  else:
    dogs += 1

print("number of cats: " + str(cats))
print("number of dogs: " + str(dogs))
```

    number of cats: 1000
    number of dogs: 1000


Because we have equal amounts of dog and cat images, the baseline model randomly guesses cat 50% of the time and dog the other 50% of time. Therefore the baseline model is 50% accurate. We can definitely do better, so let's work to improve our model!

### First Model
Let's go ahead and experiment a bit with TensorFlow's different methods for creating machine learning models. We will initialize a model using `tf.keras.Sequential` and add various labels. 

The `Conv2D` layers make use of convolutional kernels to extract key features from the training images. As the model trains, it becomes more adept at recognizing the most important features of the images that can be used to determine the difference between a dog and a cat. The `MaxPooling2D` layers then summarize and reduce the amount of data obtained by the previous layer. `Conv2D` and `MaxPooling2D` layers are often used together. We also incorporate `Dropout` layers throughout our model to protect agains overfitting. The `Flatten` layer converts the data from 2D to 1D data. Once our data is 1D, we can then pass it through the `Dense` layers which make the actual prediction as to what the image is. The final layer is `layers.Dense(2)` because we have 2 classes of data: dogs and cats.

Before deciding on using this specific model, I did some experimenting to improve the accuracy! I added and removed `Conv2D` and `MaxPooling2D` layers as well as changed the parameters in the `Dropout` layer. 


```python
model1 = tf.keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(2),
])
```

Now we need to compile and fit our model to our dataset.


```python
model1.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 7s 90ms/step - loss: 0.6933 - accuracy: 0.4830 - val_loss: 0.6931 - val_accuracy: 0.5087
    Epoch 2/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6933 - accuracy: 0.4780 - val_loss: 0.6932 - val_accuracy: 0.4864
    Epoch 3/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6933 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5012
    Epoch 4/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5037
    Epoch 5/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5050
    Epoch 6/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6932 - accuracy: 0.4820 - val_loss: 0.6932 - val_accuracy: 0.4913
    Epoch 7/20
    63/63 [==============================] - 5s 83ms/step - loss: 0.6932 - accuracy: 0.4830 - val_loss: 0.6932 - val_accuracy: 0.4963
    Epoch 8/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6932 - accuracy: 0.4860 - val_loss: 0.6931 - val_accuracy: 0.5037
    Epoch 9/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6933 - accuracy: 0.4870 - val_loss: 0.6931 - val_accuracy: 0.5062
    Epoch 10/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6932 - accuracy: 0.4850 - val_loss: 0.6932 - val_accuracy: 0.4950
    Epoch 11/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6933 - accuracy: 0.4660 - val_loss: 0.6933 - val_accuracy: 0.4901
    Epoch 12/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6933 - accuracy: 0.4830 - val_loss: 0.6931 - val_accuracy: 0.5012
    Epoch 13/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6932 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5099
    Epoch 14/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6932 - accuracy: 0.4870 - val_loss: 0.6932 - val_accuracy: 0.4963
    Epoch 15/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000
    Epoch 16/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6932 - accuracy: 0.4790 - val_loss: 0.6931 - val_accuracy: 0.5000
    Epoch 17/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6932 - accuracy: 0.4860 - val_loss: 0.6932 - val_accuracy: 0.4988
    Epoch 18/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6932 - accuracy: 0.4840 - val_loss: 0.6931 - val_accuracy: 0.5050
    Epoch 19/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6932 - accuracy: 0.4810 - val_loss: 0.6931 - val_accuracy: 0.5012
    Epoch 20/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6932 - val_accuracy: 0.4963


As can be seen below, **the accuracy of our model stabilized to around 50% during training.** However, it looks like our validation accuracy is significantly lower than our accuracy during training. Therefore we suspect that overfitting may be occurring in `model1`.


```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f7ce0422810>




    
![image-example.png](/images/output_15_1.png)    


Lastly, we will go ahead and evaluate our model on our unseen testing data. As can be seen, we got an accuracy of 54%! This is slightly better than our baseline model, but it is clear that overfitting is a huge issue. 


```python
model1_score = model1.evaluate(test_dataset)
```

    6/6 [==============================] - 1s 57ms/step - loss: 0.6930 - accuracy: 0.5417


### Model with Data Augmentation

Our next step is to add some data augmentation layers to our model. In doing so, we slightly modify images in our training set by rotating or flipping the images. We do this because we need our model to be able to distinguish between dogs and cats regardless of the orientation of the image. By adding the following layers, we will hopefully increase our testing accuracy. 


For our first layer, we will flip our image by reflecting across the y axis. The plot below is a visualization of what theser flipped images look like.


```python
flip = tf.keras.Sequential([
  tf.keras.layers.RandomFlip("horizontal_and_vertical")
])
```


```python
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = flip(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')
```


    
![image-example.png](/images/output_20_0.png)
    


Our next layer randomly rotates our image. Once again we will visualize what this layer does with our images on the plot below


```python
random_rotation = tf.keras.Sequential([
  tf.keras.layers.RandomRotation(0.5),
])
```


```python
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = random_rotation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')
```


    
![image-example.png](/images/output_23_0.png)
    


Finally, let's incorporate these new layers into a new model! We will follow the same process as we did for model 1: initialize the model, compile the model, visualize the training history, and then finally find the testing accuracy of the model.


```python
model2 = tf.keras.Sequential([
    tf.keras.layers.RandomFlip('horizontal'),                         
    tf.keras.layers.RandomRotation(0.2),                    
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(2),
])
```

Time to train our model!


```python
model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 17s 91ms/step - loss: 46.4712 - accuracy: 0.4840 - val_loss: 0.6927 - val_accuracy: 0.4926
    Epoch 2/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.7049 - accuracy: 0.5260 - val_loss: 0.6924 - val_accuracy: 0.4963
    Epoch 3/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.6956 - accuracy: 0.5375 - val_loss: 0.6897 - val_accuracy: 0.5037
    Epoch 4/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.6938 - accuracy: 0.5235 - val_loss: 0.6893 - val_accuracy: 0.5396
    Epoch 5/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.6959 - accuracy: 0.5080 - val_loss: 0.6914 - val_accuracy: 0.5223
    Epoch 6/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.6938 - accuracy: 0.5100 - val_loss: 0.6911 - val_accuracy: 0.5396
    Epoch 7/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.6909 - accuracy: 0.5290 - val_loss: 0.6881 - val_accuracy: 0.5557
    Epoch 8/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.6952 - accuracy: 0.5050 - val_loss: 0.6896 - val_accuracy: 0.4926
    Epoch 9/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6901 - val_accuracy: 0.5582
    Epoch 10/20
    63/63 [==============================] - 7s 105ms/step - loss: 0.6895 - accuracy: 0.5185 - val_loss: 0.6873 - val_accuracy: 0.5396
    Epoch 11/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.6954 - accuracy: 0.4995 - val_loss: 0.6922 - val_accuracy: 0.5186
    Epoch 12/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.6879 - accuracy: 0.5355 - val_loss: 0.6891 - val_accuracy: 0.5384
    Epoch 13/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.6923 - accuracy: 0.5010 - val_loss: 0.6918 - val_accuracy: 0.4975
    Epoch 14/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6897 - accuracy: 0.5150 - val_loss: 0.6908 - val_accuracy: 0.4876
    Epoch 15/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.6887 - accuracy: 0.5005 - val_loss: 0.6888 - val_accuracy: 0.4765
    Epoch 16/20
    63/63 [==============================] - 6s 91ms/step - loss: 0.6864 - accuracy: 0.5285 - val_loss: 0.6899 - val_accuracy: 0.4975
    Epoch 17/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.6858 - accuracy: 0.5195 - val_loss: 0.6874 - val_accuracy: 0.5037
    Epoch 18/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.6875 - accuracy: 0.5415 - val_loss: 0.6919 - val_accuracy: 0.4913
    Epoch 19/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.6863 - accuracy: 0.5390 - val_loss: 0.6918 - val_accuracy: 0.4876
    Epoch 20/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.6894 - accuracy: 0.5195 - val_loss: 0.6960 - val_accuracy: 0.4901


As can be seen, **the validation accuracy of model2 during training stabilizes to around 55%.** This validation accuracy is actually slightly lower than the validation accuracy we obtained with model1. The validation accuracy is still lower than the accuracy when we train our model, however the difference in values is not quite as significant. Overfitting is of course still a possible concern, but this model is most likely less overfit than model1 was.


```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f7ced899290>





![image-example.png](/images/output_29_1.png)
    


We also note that the accuracy of the model on our testing data is 55%. This isn't a huge improvement in accuracy from `model1`, so we can definitely continue to improve upon what we already have.


```python
model2_score = model2.evaluate(test_dataset)
```

    6/6 [==============================] - 1s 51ms/step - loss: 0.6837 - accuracy: 0.5573


### Data Preprocessing

Our next task is to speed up the training speed of our model. Right now the images in our training data have pixels with RGB values between 0 and 255 to distinguish between colors. If we scale these values down to be between 0 and 1, our model will have an easier time training and it will be able to focus more on differentiating between image features. This should increase our accuracy in the long run!


The following code initializes a preprocessing layer which we will add to our model.


```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```


```python
model3 = tf.keras.Sequential([
    preprocessor,
    tf.keras.layers.RandomFlip('horizontal'),                         
    tf.keras.layers.RandomRotation(0.2),                    
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(2),
])
```

Now we will train our model and visualize the training history!


```python
model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 8s 96ms/step - loss: 0.8721 - accuracy: 0.4920 - val_loss: 0.6723 - val_accuracy: 0.5718
    Epoch 2/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6626 - accuracy: 0.5660 - val_loss: 0.6724 - val_accuracy: 0.5371
    Epoch 3/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6554 - accuracy: 0.5765 - val_loss: 0.6624 - val_accuracy: 0.6040
    Epoch 4/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6366 - accuracy: 0.6355 - val_loss: 0.6406 - val_accuracy: 0.6300
    Epoch 5/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6228 - accuracy: 0.6310 - val_loss: 0.6121 - val_accuracy: 0.6510
    Epoch 6/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6109 - accuracy: 0.6500 - val_loss: 0.6206 - val_accuracy: 0.6411
    Epoch 7/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6037 - accuracy: 0.6755 - val_loss: 0.6298 - val_accuracy: 0.6324
    Epoch 8/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6017 - accuracy: 0.6720 - val_loss: 0.5840 - val_accuracy: 0.6869
    Epoch 9/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5839 - accuracy: 0.6810 - val_loss: 0.6167 - val_accuracy: 0.6436
    Epoch 10/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5735 - accuracy: 0.6910 - val_loss: 0.5819 - val_accuracy: 0.6757
    Epoch 11/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5718 - accuracy: 0.6990 - val_loss: 0.5838 - val_accuracy: 0.6844
    Epoch 12/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.5581 - accuracy: 0.7120 - val_loss: 0.5568 - val_accuracy: 0.7017
    Epoch 13/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.5454 - accuracy: 0.7230 - val_loss: 0.8042 - val_accuracy: 0.6473
    Epoch 14/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5677 - accuracy: 0.7165 - val_loss: 0.5616 - val_accuracy: 0.7030
    Epoch 15/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5404 - accuracy: 0.7230 - val_loss: 0.5664 - val_accuracy: 0.7067
    Epoch 16/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.5383 - accuracy: 0.7180 - val_loss: 0.5726 - val_accuracy: 0.7092
    Epoch 17/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5328 - accuracy: 0.7275 - val_loss: 0.5397 - val_accuracy: 0.7228
    Epoch 18/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.5033 - accuracy: 0.7475 - val_loss: 0.5308 - val_accuracy: 0.7376
    Epoch 19/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.5014 - accuracy: 0.7585 - val_loss: 0.5434 - val_accuracy: 0.7240
    Epoch 20/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.4918 - accuracy: 0.7490 - val_loss: 0.5385 - val_accuracy: 0.7228



```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f7c6d011050>




    
![image-example.png](/images/output_37_1.png)
    


We are pretty pleased with these results, as the **validation accuracy of our model stabilized to around 74%.** This is a significant improvement from our baseline model which only had an accuracy of 50%. Similar to `model2`, it is definitely possible that overfitting is still happening, as the validation accuracy was often lower than the training accuracy when we compiled our model. However, the two values were relatively similar throughout the training process, so we were able to minimize at least some of the overfitting.


```python
model3_score = model3.evaluate(test_dataset)
```

    6/6 [==============================] - 1s 46ms/step - loss: 0.5543 - accuracy: 0.7448


### Transfer Learning

For our last model we will make use of someone else'e machine learning model and apply it to our task. The following code initializes the `base_model_layer` from `MobileNextV2`. We will then incorporate the layer into a model specific to our task and follow the same process that we did for the past 3 models!


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5
    9412608/9406464 [==============================] - 0s 0us/step
    9420800/9406464 [==============================] - 0s 0us/step



```python
model4 = tf.keras.Sequential([
    preprocessor,
    tf.keras.layers.RandomFlip('horizontal'),                         
    tf.keras.layers.RandomRotation(0.2),
    base_model_layer,                    
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(2),
])

model4.summary()
```

    Model: "sequential_5"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model (Functional)          (None, 160, 160, 3)       0         
                                                                     
     random_flip_3 (RandomFlip)  (None, 160, 160, 3)       0         
                                                                     
     random_rotation_3 (RandomRo  (None, 160, 160, 3)      0         
     tation)                                                         
                                                                     
     model_1 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                     
     dropout_6 (Dropout)         (None, 5, 5, 1280)        0         
                                                                     
     flatten_3 (Flatten)         (None, 32000)             0         
                                                                     
     dense_6 (Dense)             (None, 64)                2048064   
                                                                     
     dense_7 (Dense)             (None, 2)                 130       
                                                                     
    =================================================================
    Total params: 4,306,178
    Trainable params: 2,048,194
    Non-trainable params: 2,257,984
    _________________________________________________________________


Okay wow! So there is a lot of complexity hidden in `base_model_layer` as we need to train 2,048,194 parameters. Let's get to it then!


```python
model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 11s 113ms/step - loss: 0.3353 - accuracy: 0.9035 - val_loss: 0.0660 - val_accuracy: 0.9691
    Epoch 2/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1192 - accuracy: 0.9580 - val_loss: 0.0544 - val_accuracy: 0.9839
    Epoch 3/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.0986 - accuracy: 0.9605 - val_loss: 0.0474 - val_accuracy: 0.9790
    Epoch 4/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.1172 - accuracy: 0.9590 - val_loss: 0.0488 - val_accuracy: 0.9814
    Epoch 5/20
    63/63 [==============================] - 6s 91ms/step - loss: 0.0691 - accuracy: 0.9720 - val_loss: 0.0477 - val_accuracy: 0.9839
    Epoch 6/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.0647 - accuracy: 0.9740 - val_loss: 0.0491 - val_accuracy: 0.9827
    Epoch 7/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.0911 - accuracy: 0.9670 - val_loss: 0.0529 - val_accuracy: 0.9802
    Epoch 8/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.0839 - accuracy: 0.9725 - val_loss: 0.0461 - val_accuracy: 0.9876
    Epoch 9/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.0569 - accuracy: 0.9785 - val_loss: 0.0487 - val_accuracy: 0.9839
    Epoch 10/20
    63/63 [==============================] - 7s 102ms/step - loss: 0.0496 - accuracy: 0.9810 - val_loss: 0.0475 - val_accuracy: 0.9864
    Epoch 11/20
    63/63 [==============================] - 6s 91ms/step - loss: 0.0644 - accuracy: 0.9755 - val_loss: 0.0532 - val_accuracy: 0.9814
    Epoch 12/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 0.0472 - val_accuracy: 0.9851
    Epoch 13/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.0608 - accuracy: 0.9740 - val_loss: 0.0625 - val_accuracy: 0.9814
    Epoch 14/20
    63/63 [==============================] - 6s 92ms/step - loss: 0.0557 - accuracy: 0.9820 - val_loss: 0.0557 - val_accuracy: 0.9802
    Epoch 15/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.0443 - accuracy: 0.9835 - val_loss: 0.0563 - val_accuracy: 0.9839
    Epoch 16/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.0352 - accuracy: 0.9885 - val_loss: 0.0607 - val_accuracy: 0.9802
    Epoch 17/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.0463 - accuracy: 0.9815 - val_loss: 0.0500 - val_accuracy: 0.9839
    Epoch 18/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.0301 - accuracy: 0.9890 - val_loss: 0.0530 - val_accuracy: 0.9814
    Epoch 19/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.0492 - accuracy: 0.9795 - val_loss: 0.0568 - val_accuracy: 0.9802
    Epoch 20/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.0345 - accuracy: 0.9855 - val_loss: 0.0518 - val_accuracy: 0.9851


By incorporating the `base_model_layer` into our model, w**e were able to obtain a validation accuracy of approximately 98%,** so we are fairly pleased! We have come a long way since our baseline model which had a validation accuracy of 50%. While overfitting is always a concern, it appears that we have done our best to minimize it in this model as the training and validation accuracy stabilized to be very similar values.


```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f7bf8c338d0>





![image-example.png](/images/output_46_1.png)
    


When we evaluate `model4` on our testing data, we obtain an accuracy of 97%. This means that our model was able to correctly differentiate between cats and dogs 97% of the time, so we are pretty happy with these results!


```python
model4_score = model4.evaluate(test_dataset)
```

    6/6 [==============================] - 1s 62ms/step - loss: 0.0510 - accuracy: 0.9792


### Score on Test Data

Let's take one last look at the testing accuracy that we were able to obtain from our models!


```python
print("model 1 score: " + str(round(model1_score[1],2)))
print("model 2 score: " + str(round(model2_score[1],2)))
print("model 3 score: " + str(round(model3_score[1],2)))
print("model 4 score: " + str(round(model4_score[1],2)))

```

    model 1 score: 0.54
    model 2 score: 0.56
    model 3 score: 0.74
    model 4 score: 0.98


Thank you for reading! I'll see you next week for our last blog post.

~ Emma
